# LLM-ACT-R
This ongoing project aims to develop a novel hybrid architecture called LLM-ACTR designed to address the limitations of Large Language Models (LLMs) in decision-making.

## Structure

The repository is organized into the following main directories:

- **`/VSM-ACTR`**: This directory hosts all resources related to the VSM-ACTR cognitive model.
- **`/Notebooks`**: Contains notebooks for finetuning, training, evaluating, and visualizing data and model outputs.
- **`/docs`**: Documentation related to the project, including setup, usage, and examples.

### VSM-ACTR

- **`/model`**: Core model file.
- **`/raw data`**: output sample from cognitive model.
- **`/processed data`**: preprocessed dataset

### Data Science Notebooks

- **`/feature extraction`**: Notebooks for feature extraction for behavior prediction.
- **`/finetuning`**: Notebooks for fine-tuning for knowledge transfer.
- **`/baseline`**: Notebooks with two baselines.

## Getting Started

## Cite
```bibtex

@forthcoming{wu2024vsmactr,
  title={VSM-ACT-R: Toward Using Cognitive Architecture For Manufacturing Solutions},
  author={Wu, Siyu and Oltramari, Alessandro and Ritter, Frank E},
  booktitle={paper accepted at 17th International Conference on Social Computing, Behavioral-Cultural Modeling & Prediction and Behavior Representation in Modeling and Simulation (SBP-BRIMs)},
  year={2024},
  month={June}
}
```
```bibtex
@inproceedings{wu2024llama,
  title={LLAMA-ACT-R, a Neuro-Symbolic Architecture (ACT-R) for LLM Decision Making},
  author={Wu, Siyu and Giles, C. Lee and Ritter, Frank E.},
  booktitle={Poster Presented In Annual Ethical AI Symposium},
  year={2024},
  organization={University of Michigan Institute for Data Science}
}
```
